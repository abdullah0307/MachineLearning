{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYeZzUxHb6C0"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-a6Cd5kb6C4"
   },
   "source": [
    "The purpose of this task is to hone your matplotlib skills, and expose you to an elementary multiple linear regression problem. \n",
    "\n",
    "The provided data has been generated from a simple linear model, but some random noise has been added. Your goal is to perform multivariate ordinary least squares linear regression to determine the Best Linear Unbiased Estimators (BLUE) for the model (that is, you must calculate the model parameters for a linear regression model).  There will be some irreducible error due to the noise that was injected into the data, therefore we will never be able to exactly recover the \"true model parameters\".  However, the optimal model parameters computed via the linear regression analysis are sufficiently accurate that you will be able to infer the true model parameters for yourslef!\n",
    "\n",
    "Here are the steps you will take:\n",
    "\n",
    "1. Create the following figure using matplotlib, which plots the data from the file called `MultipleLinearRegressionData.csv`.\n",
    "2. Perform linear regression to calculate the optimal ordinary least squares regression model parameters.\n",
    "3. Recreate the first figure by adding the best fit curve to all subplots.\n",
    "4. Infer the true model parameters.\n",
    "\n",
    "Below is the first figure you must emulate:\n",
    "\n",
    "<img src=\"LinearDataPlot.png\" width =\"800\" />\n",
    "\n",
    "Below is the second figure you must emulate:\n",
    "\n",
    "<img src=\"LinearDataPlot_Curve.png\" width =\"800\" />\n",
    "\n",
    "Each of the two figures has four subplots.  Note the various viewing angles that each subplot presents - you can achieve this with the [view_init()](https://jakevdp.github.io/PythonDataScienceHandbook/04.12-three-dimensional-plotting.html) method. Use the same color scheme for the datapoints shown here, which is called `jet`.  Be sure to label your axes as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WxdhV9-2b6C5"
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "FOLDER = \"figures\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, FOLDER)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaMQWFxCb6C6"
   },
   "source": [
    "# Import Data\n",
    "\n",
    "Begin by importing the data from the file called `MultipleLinearRegression.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L26qHXBUb6C7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fileName = \"MultipleLinearRegression.csv\"\n",
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVUSWdCMb6C7"
   },
   "source": [
    "# Create First Image \n",
    "\n",
    "Use the [scatter3D](https://jakevdp.github.io/PythonDataScienceHandbook/04.12-three-dimensional-plotting.html) to plot in three dimensions.  Create four [subplots](https://matplotlib.org/3.1.0/gallery/recipes/create_subplots.html) with the appropriate viewing angles using the [view_init()](https://jakevdp.github.io/PythonDataScienceHandbook/04.12-three-dimensional-plotting.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSPcguB7b6C8"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvmVmGJjb6C9"
   },
   "source": [
    "# Train Linear Regression Model\n",
    "\n",
    "From the `sklearn.linear_model` library, import the `LinearRegression` class.  Instantiate an object of this class called `model`, and fit it to the data. The `x` and `y` coordinates will be your features and `z` will be your response. \n",
    "\n",
    "Print the optimal model parameters to the screen by completing the following `print()` statements.\n",
    "\n",
    "**Note:** Since we are not concerned with generalization error in this assignment, we will not split our data into training and test sets. In 'real-world' projects, you would want to split your data to see how your model performs with data that it has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnOzJ2xzb6C9"
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "### ENTER CODE HERE ###\n",
    "### ENTER CODE HERE ###\n",
    "\n",
    "print(\"Model Coefficients: \", ### ENTER CODE HERE ###)\n",
    "print(\"Model Intercept : \", ### ENTER CODE HERE ###)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hMHNVe4b6C-"
   },
   "source": [
    "# Create Second Image\n",
    "\n",
    "Now that we have fit our model, which means that we have computed the optimal model parameters, we can use our model to plot the regression line for the data.  Below, I supply you with `x_fit` and `y_fit` that represent the x- and y-data of the regression line, respectively.  All we need to do next is ask the model to predict a `z_fit` value for each `x_fit` and `y_fit` pair by invoking the model's `predict()` method.  This should make sense when you consider the ordinary least squares linear regression equation for calculating `z_fit`:\n",
    "\n",
    "$$ z_{fit} = \\hat{\\theta}_0 + \\hat{\\theta}_1 x_{fit} + \\hat{\\theta}_2 y_{fit} $$\n",
    "\n",
    "where $ \\hat{\\theta}_i $ are the computed model parameters.  You must use `x_fit` and `y_fit` as features to be passed to the model's `predict()` method, which will return `z_fit` as determined by the above equation.  Once you obtain `z_fit`, you are ready to plot the regression line by plotting it against `x_fit` and `y_fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DplGvDbhb6C-"
   },
   "outputs": [],
   "source": [
    "# Plot Curve Fit\n",
    "x_fit = np.linspace(0,21,1000)\n",
    "y_fit = x_fit\n",
    "\n",
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "den_Kodsb6C-"
   },
   "source": [
    "Recreate the first image, but plot the line of best fit in each of the subplots as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qXCpkBQb6C_"
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9auLlZcb6C_"
   },
   "source": [
    "# Infer the True Model Parameters\n",
    "\n",
    "I defined the equation of a line plus a random Gaussian noise term in order to generate this data - this is the \"true\" model (minus the noise term). You took that noisy data and performed a regression analysis to obtain estimates of the \"true\" model parameters. The noise in the data prevents you from computing those \"true\" model parameters exactly - there is some irreducible error. Instead, the linear regression model only gives you the Best Linear Unbiased Estimators (BLUE) for the \"true\" model parameters. \n",
    "\n",
    "The true model parameters that I selected are <b>integer values</b>. Given this information, you must look at the model coefficients that the regression algorithm computed, and infer what the true model parameters are. You may \"hard-code\" these values into the below print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PilqJx_Ob6C_"
   },
   "outputs": [],
   "source": [
    "print(\"True Model Coefficients: \", \"### ENTER CODE HERE ###\")\n",
    "print(\"True Model Intercept : \", \"### ENTER CODE HERE ###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twe2o34yb6DA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
